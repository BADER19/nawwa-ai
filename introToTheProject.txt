ğŸ§­ Introduction for the Coding Agent

Youâ€™re not building a traditional presentation tool.
Youâ€™re building an instant, AI-powered visual presentation platform â€” a system that replaces PowerPoint, slides, and static prep altogether.

The core principle is simple but powerful:

The user speaks or types an idea, and the system instantly creates visuals â€” charts, diagrams, shapes, math graphs, or annotated scenes â€” right in front of them.

No prebuilt slides.
No templates.
No wasted prep time.

The system provides a live, intelligent workspace â€” a blank visual canvas waiting for the userâ€™s ideas.
They can:

Speak to the system in real time.

See the visuals appear instantly on-screen.

Save everything into a workspace they can revisit, edit, or present again later.

In practice, this means:

A teacher can say â€œshow a parabola and its tangent at x=2â€ and the board draws it live.

A founder can say â€œdraw our user funnelâ€ and a clean flowchart appears.

A scientist can say â€œplot temperature vs. time for dataset Aâ€ and a chart animates instantly.

Itâ€™s not PowerPoint.
Itâ€™s thinking and speaking turned visual â€” instantly.

ğŸ§  What Youâ€™re Building

Youâ€™re creating a real-time, multimodal visualization SaaS, built around:

Natural language understanding â€” powered by OpenAI GPT-4o.

Dynamic visual rendering â€” via a canvas engine (Fabric.js).

Persistent workspaces â€” backed by a Postgres database for saving sessions.

Modular architecture â€” backend API (FastAPI), frontend app (Next.js), cache (Redis).

Your job is to make this entire pipeline work end-to-end, cleanly, inside Docker â€” so a user can type or speak and see visuals appear instantly.

âš™ï¸ Stage 1 Objective

Build the core foundation of this system â€” the first working vertical slice.
It must:

Take text input (voice optional for now).

Use OpenAI GPT-4o to interpret the command.

Generate a structured JSON describing visuals (e.g., shapes, colors, positions).

Render those visuals on a canvas (Fabric.js) in real time.

Save and load workspaces from PostgreSQL.

Keep everything modular, documented, and production-grade.
Frontend design is plain â€” we will hire a UI engineer later.
Your task is functionality, not styling.

ğŸ§© Tech Stack Overview
Layer	Tech
Frontend	Next.js (React + TS), Fabric.js, TailwindCSS
Backend	FastAPI (Python), OpenAI API, SQLAlchemy
Database	PostgreSQL
Cache	Redis
Infra	Docker + docker-compose
Auth	JWT (basic)
Speech (later)	OpenAI Whisper API
ğŸ§± Stage 1 Deliverables

Backend API

/auth â†’ signup/login.

/visualize â†’ accepts natural language input, returns JSON visual spec.

/workspace â†’ save/load workspace data.

Integration with OpenAI API.

Uses SQLAlchemy + Postgres for persistence.

Redis for caching (optional but configured).

Frontend

Minimal Next.js app with:

Landing page /

Login /auth

Workspace /app â†’ contains chat input + canvas.

Input box sends command to /visualize.

Fabric.js renders visuals described by backend JSON.

â€œSaveâ€ button stores workspace via /workspace/save.

Infrastructure

Docker Compose setup (backend, frontend, Postgres, Redis).

Environment variables stored in .env.

One command (docker-compose up) brings everything online.

Validation

A user can:

Sign up

Type â€œdraw a blue circleâ€

See the circle appear on the canvas

Save workspace

Reload workspace and see the same visual

When that loop works, Stage 1 is complete.

âš¡ï¸ Constraints

No fancy design or animations.

No billing, OAuth, or collaboration yet.

Focus purely on the flow: input â†’ AI â†’ visual â†’ save.

Once this foundation is stable, weâ€™ll build Stage 2: Smart Understanding & Rendering (context awareness, more visual types, workspace intelligence).









"http://localhost:28001/docs#/admin/update_user_admin_users__user_id__put"